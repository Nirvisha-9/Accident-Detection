{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"final_project.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"HlmVY55Cmy7l"},"source":["#download the retinanet api(folders)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"47kcsU7QmuVC"},"source":["!git clone 'https://github.com/fizyr/keras-retinanet.git'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C3ncX1RN5Mtf"},"source":["##going to retinanet folder"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NfvfbzMayLzD","outputId":"ebb3db90-417c-4bd7-9b16-74515844b2c3"},"source":["cd /content/drive/MyDrive/keras-retinanet "],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/keras-retinanet\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"75Zz1RJa4-yL"},"source":["##installing the requirements"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"edNKeKB-5VCj","outputId":"52179fe8-e79d-4339-cee7-3b846fab1c83"},"source":["!pip install . --user"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Processing /content/drive/MyDrive/keras-retinanet\n","Requirement already satisfied: keras-resnet==0.2.0 in /root/.local/lib/python3.7/site-packages (from keras-retinanet==1.0.0) (0.2.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (1.15.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (1.19.5)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (0.29.22)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (7.1.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (4.1.2.30)\n","Requirement already satisfied: progressbar2 in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (3.38.0)\n","Requirement already satisfied: keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.4.3)\n","Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2->keras-retinanet==1.0.0) (2.5.6)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.13)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.10.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.4.1)\n","Building wheels for collected packages: keras-retinanet\n","  Building wheel for keras-retinanet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-retinanet: filename=keras_retinanet-1.0.0-cp37-cp37m-linux_x86_64.whl size=168427 sha256=5dc110018ff7a4b29c35810de8aed9ee096fb8b08de1dd3c567c6c8cf285b930\n","  Stored in directory: /root/.cache/pip/wheels/16/cc/dc/f6b0df540a02e47f927dd0d9ec6e3f98a0e724f68798846d24\n","Successfully built keras-retinanet\n","Installing collected packages: keras-retinanet\n","  Found existing installation: keras-retinanet 1.0.0\n","    Uninstalling keras-retinanet-1.0.0:\n","      Successfully uninstalled keras-retinanet-1.0.0\n","\u001b[33m  WARNING: The scripts retinanet-convert-model, retinanet-debug, retinanet-evaluate and retinanet-train are installed in '/root/.local/bin' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n","Successfully installed keras-retinanet-1.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xunk3H6bCQ6y","outputId":"09c1ae51-bbf8-48dd-ca02-895a279bb5ea"},"source":["!python setup.py build_ext --inplace"],"execution_count":null,"outputs":[{"output_type":"stream","text":["running build_ext\n","skipping 'keras_retinanet/utils/compute_overlap.c' Cython extension (up-to-date)\n","copying build/lib.linux-x86_64-3.7/keras_retinanet/utils/compute_overlap.cpython-37m-x86_64-linux-gnu.so -> keras_retinanet/utils\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9BP_bz-EnfsZ"},"source":["# Download the helper library from https://www.twilio.com/docs/python/install\n","#for sending messages"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6GdiPR4Kne1q","outputId":"6dfa45ca-3479-48b9-c80f-951da60f1601"},"source":["!pip install twilio"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: twilio in /usr/local/lib/python3.7/dist-packages (6.55.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from twilio) (1.15.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from twilio) (2018.9)\n","Requirement already satisfied: PyJWT==1.7.1 in /usr/local/lib/python3.7/dist-packages (from twilio) (1.7.1)\n","Requirement already satisfied: requests>=2.0.0; python_version >= \"3.0\" in /usr/local/lib/python3.7/dist-packages (from twilio) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0; python_version >= \"3.0\"->twilio) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0; python_version >= \"3.0\"->twilio) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0; python_version >= \"3.0\"->twilio) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0; python_version >= \"3.0\"->twilio) (2.10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oDMOXJ2PDic_","outputId":"29e20a60-e126-45db-aa2e-2eefad370def"},"source":["'''For every new object detected in the current frame:\n","    1.1 For every old object from the previous frame:\n","        1.1.1 Find an old object such that the distance between this old object and new object is the least\n","              among all combinations of old object and new object pairs.\n","    1.2 The old object with the least distance to the new object is most certainly the same object. This \n","        is because an object can only move so far between subsequent frames so this distance will almost\n","        always be smaller than the distance between 2 different objects.\n","    1.3 Assign the new object the index of the corresponding old object.\n","    1.4 Update new object's number of frames detected and vectors accordingly\n","    \n","    we check if an old object has already been assigned to a new object. If this is the case and there\n","is a conflict between assigning two new objects to a single old object, we will compare the distances between\n","the two pairs and decide which new object the old object actually corresponds to. The incorrect new object is \n","then marked as \"not found\" and will later be assigned a completely new index.'''\n","\n","\n","#importing packages\n","import tensorflow as tf\n","from tensorflow import keras\n","import cv2                                    #for image processing\n","import numpy as np\n","from google.colab.patches import cv2_imshow    #to show images in colab\n","from tensorflow.keras.models import load_model \n","\n","#packages from retinanet\n","from keras_retinanet import models\n","from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n","from keras_retinanet.utils.visualization import draw_box, draw_caption\n","from keras_retinanet.utils.colors import label_color\n","\n","import os\n","from os.path import isfile, join\n","\n","from twilio.rest import Client\n","\n","model_path=\"inference_graphs/crash_detection_model.h5\"    #weights location\n","model=models.load_model(model_path, backbone_name='resnet50') #load the model\n","\n","pat='/content/drive/MyDrive/keras-retinanet/videos/junction_crashes1.mp4'   #video source\n","\n","source=cv2.VideoCapture(pat)          #start video processing\n","\n","\n","##setting all parameters for video \n","# l=list(pat.split('/'))[-1]\n","# l=list(l.split('.'))[0]\n","# out_path='/content/drive/MyDrive/keras-retinanet/out_videos/'+l+\".mp4\"  #video output location\n","# fps = 16  #video frames per second\n","# #getting size of 1st frame to set size for video\n","# ret,img=source.read()   \n","# rows = img.shape[0]\n","# cols = img.shape[1]\n","# if rows < cols:\n","#     padding = int((cols - rows) / 2)\n","#     img = cv2.copyMakeBorder(img, padding, padding, 0, 0, cv2.BORDER_CONSTANT, (0, 0, 0))\n","# elif rows > cols:\n","#     padding = int((rows - cols) / 2)\n","#     img = cv2.copyMakeBorder(img, 0, 0, padding, padding, cv2.BORDER_CONSTANT, (0, 0, 0))\n","# draw = img.copy()\n","# height, width, layers = draw.shape #getting dimension of image\n","# size = (width,height)\n","# out = cv2.VideoWriter(out_path,cv2.VideoWriter_fourcc(*'DIVX'), fps, size) #start video input\n","# source=cv2.VideoCapture(pat)          #restart video processing again\n","\n","'''frame_objects structure for EACH object:\n","Index 0: Tuple for the midpoint of the object\n","Index 1: Number of frames object has been consecutively detected for\n","Index 2: queue to store midpoints of the object over the past 5 frames. Used for vector calculation\n","Index 3: for previous frame this stores the array index of the new object that this old object has been assigned to.\n","         for current frame this stores the index of previous frame object to which this new object is attached\n","         This is used to fix any conflicts between 2 or more new objects that have been assigned to the same\n","         old object(this happens when a new object comes). \n","Index 4: Magnitude of vector for the object of current frame'''\n","images=[]                             #array to store each frame to build video\n","prev=[]                               #stores objects of previous frame\n","cur=[]                                #stores objects of  current frame\n","\n","\n","#function to calculate distance between two points\n","def dist(p1,p2):\n","  x=(p1[0]-p2[0])**2\n","  y=(p1[1]-p2[1])**2\n","  return (x+y)**0.5\n","\n","\n","f=5\n","#message sending funtion\n","#dont use unnecessaryly\n","def notify(id):\n","  global f\n","  if f>0:\n","    print('inside')\n","    f-=1\n","    # Your Account Sid and Auth Token from twilio.com/console\n","    client = Client(\"AC597573dbb155e6900c95ba0a07315393\", \"f14e13ad06f422680560d5470798c6d6\")  #initialize client with(Account Sid,Auth Token)\n","    msg=\"--\\nCRASH OCCURED  \\n view crash image having ID **img{}_jpg** at : \\n https://drive.google.com/drive/folders/1PpyH8W6tvbGurWS5hrgdWnvxGU3jQFrp?usp=sharing\".format(id)\n","    client.messages.create(from_=\"+17028304663\",\n","                                      to=\"+919247446977\",\n","                                      body=msg ,\n","                                     \n","                                      )\n","\n","count=0     #frame count\n","count_crash=0   #crash frame count\n","\n","#loop to process video frame by frame\n","while(True):\n","    \n","    ret,img=source.read()   #reading each frame\n","\n","    if(ret==False):         #if frame not read =>end of video so break loop\n","      break\n","   \n","    # Making input image square by padding it. This is because our model was trained on square\n","    # images. Changing the aspect ratio of input images would greatly reduce accuracy\n","    rows = img.shape[0]\n","    cols = img.shape[1]\n","    if rows < cols:\n","        padding = int((cols - rows) / 2)\n","        img = cv2.copyMakeBorder(img, padding, padding, 0, 0, cv2.BORDER_CONSTANT, (0, 0, 0))\n","    elif rows > cols:\n","        padding = int((rows - cols) / 2)\n","        img = cv2.copyMakeBorder(img, 0, 0, padding, padding, cv2.BORDER_CONSTANT, (0, 0, 0))\n","    \n","    \n","    draw = img.copy() #storing a copy of frame to use for output\n","\n","    #preprocessing image to apply retinanet\n","    img = preprocess_image(img)\n","    img, scale = resize_image(img,min_side=600) #minsize by default 800 but we  have imgs of 600,600 shape \n","    \n","    #apply retinanet to each frame\n","    '''Where boxes are shaped  (left,top,bottom,right)),\n","     scores is shaped (None, None) (classification score for each label) \n","     and labels is shaped (None, None) (label corresponding to the score)'''\n","\n","    boxes, scores, labels = model.predict_on_batch(np.expand_dims(img, axis=0)) #prediction using retinanet\n","    boxes /= scale   # Adjusting scale of bounding boxes since our frame is resized to 600p\n","    \n","    is_crash=False  #flag used to indicate if any one vehicle is involved in crash for in THIS frame \n","    \n","\n","    #traversing every object in the frame\n","    for box, score in zip(boxes[0], scores[0]):\n","        # We break if the score of any of our detections is below 0.95. This is because\n","        # all detections are sorted in descending order in terms of their scores.\n","        if score < 0.95:\n","            break\n","        #getting midpoint of the bounding box\n","        mid_x = int((box[2] + box[0]) / 2)\n","        mid_y = int((box[3] + box[1]) / 2)\n","\n","        #creating the frame_object structure mentioned above \n","        # for each object and add them to cur array \n","        cur.append([(mid_x,mid_y),1,[(mid_x,mid_y)],-1,0])\n","    \n","    ##check if this is initial frame(i.e if already some objects exists in prev frame or not)\n","    if len(prev)!=0:\n","      #iterate through CURRENT frame objects\n","      for i,obj in enumerate(cur):\n","        m=float('inf')\n","        pre_ind=-1\n","        #for each cur object check distance with every prev obj\n","        for e,pobj in enumerate(prev):\n","          if dist(pobj[0],obj[0])<m:\n","            m=dist(pobj[0],obj[0])\n","            pre_ind=e\n","        \n","        # pre_ind contains the INDEX of object in prev frame which has min_dict to cur object in cur frame\n","        \n","        #if that previous object is not assigned to any other cur object,then establish the dual(both sides) link\n","        if (prev[pre_ind][3]==-1): #checking if the index 3: is -1 or already assigned\n","          prev[pre_ind][3]=i  #establish connection from prev to curr\n","          cur[i][3]=pre_ind   #establish connection from curr to prev \n","\n","        #if that previous object is already assigned to any new object\n","        #check the distance between 1:previous object and its already assigned old cur_frame object\n","        #                      and  2:previous object and the new cur_frame object \n","        #establish link between objects having minimum distance                              \n","        else:\n","          #already assigned object has min_dist do nothing \n","          #else change the links between previous object and cur objects\n","          if (dist(prev[pre_ind][0],cur[i][0])<dist(prev[pre_ind][0],cur[prev[pre_ind][3]][0])):  #check if distance between previous object and the new cur object is less than previous object and its already assigned old cur object \n","\n","            cur[i][3]=pre_ind  #establish link from new cur_frame object to min_dist prev_frame object obtained above(pre_ind)\n","            cur[prev[pre_ind][3]][3]=-1  #remove link from old cur_frame object and prev_frame object obtained above(pre_ind)\n","            prev[pre_ind][3]=i  #establish link from prev object to new cur_frame object\n","\n","        \n","        #fill the remaining feilds in cur_frame objects only if they are linked to previous frame\n","        #else they are considered as new objects(and nothing more need to be done)\n","      for i,obj in enumerate(cur):\n","        if cur[i][3]!=-1: #for cur_frame objects which has a link to previous frame \n","\n","            prev_ind=cur[i][3]  ##geting prev_obj index to which cur obj is linked\n","            \n","            cur[i][1]=prev[prev_ind][1]+1  #incrementing frame count of cur object= prev+1\n","            \n","\n","            cur[i][2]=prev[prev_ind][2].copy() #copying the mid_points list of prev_frame linked object \n","            \n","            cur[i][2].append(cur[i][0])  #updating the mid points list by adding curent mid point\n","\n","            \n","            #if frame count =5 initialize the magnitude \n","            '''The vector for every object is calculated from the object's midpoint at the 1st frame, and the midpoint at\n","                the 5th frame. We store these midpoints in a deque inside prev_frame_objects and/or cur_frame_objects. \n","                The deque is kept updated every frame by removing the oldest midpoint and adding the latest midpoint'''\n","            if cur[i][1]==5:     #if obj is present for k consecutive frames then draw vector \n","                temp=cur[i][2].copy() #copying mid_points array in temp variable\n","                vector=[temp[-1][0]-temp[0][0],temp[-1][1]-temp[0][1]] #constructing vector between 1st point in mid_point array and last(latest midpoint) point in array\n","                cur[i][4]=(vector[0]**2+vector[1]**2)**(1/2) #getting the magnitude of vector(distance between points) and store in index 4 of object\n","\n","                next_p=(2*vector[0]+cur[i][0][0],2*vector[1]+cur[i][0][1])  ##calculation of next projected point \n","                cv2.circle(draw, cur[i][0], 5, (0, 0, 255), -1)     ##draw circle around vehicle\n","                cv2.line(draw, cur[i][0], next_p, (0, 255, 0), 2)   ##draw vector (from cur mid point to projected point)\n","            \n","            elif cur[i][1]>5:\n","                cur[i][2].pop(0) #remove the initial mid point as we need only the recent 3 mid points\n","                #same as above\n","                temp=cur[i][2]\n","                vector=[temp[-1][0]-temp[0][0],temp[-1][1]-temp[0][1]]\n","                cur[i][4]=(vector[0]**2+vector[1]**2)**(1/2)\n","\n","                next_p=(2*vector[0]+cur[i][0][0],2*vector[1]+cur[i][0][1])  ##calculation of next projected point \n","                cv2.circle(draw, cur[i][0], 5, (0, 0, 255), -1)     ##draw circle around vehicle\n","                cv2.line(draw, cur[i][0], next_p, (0, 255, 0), 2)   ##draw vector\n","\n","                #check the difference in prev vector magnitude and curr vector magnitude \n","                #if greater than threshold report as accident  \n","                if abs(cur[i][4]-prev[prev_ind][4])>11:     ##change in magnitude for crash to occur\n","                    cv2.circle(draw, cur[i][0], 40, (0, 0, 255), 4)   ##draw circle over crash\n","                    is_crash=True  #set crash flag as true\n","                    \n","    # print(prev)\n","    # print(cur)\n","    #by checking for all objects above if any crash occurs display text and store frame              \n","    if is_crash: #check if crash occured\n","      cv2.putText(draw,\"CRASH DETECTED\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2) ##print crash_detected on img\n","      \n","      if os.path.exists(\"/content/drive/MyDrive/keras-retinanet/crash_pics/img%d.jpg\" % count_crash): #check if old crash image with same id exists already\n","        os.remove(\"/content/drive/MyDrive/keras-retinanet/crash_pics/img%d.jpg\" % count_crash) #remove the old crash pic\n","\n","      cv2.imwrite(r\"/content/drive/MyDrive/keras-retinanet/crash_pics/img%d.jpg\" % count_crash, draw) #storing crash images\n","      #notify(count_crash)  #calling the notification function\n","      count_crash+=1  #increment crash_count\n","\n","    #remove all links from cur to prev ..so when cur becomes prev.. all links are unset for future use\n","    for ind in range(len(cur)):\n","      cur[ind][3]=-1\n","    \n","    prev=cur.copy() #copy cur to prev\n","    cur=[]   #set cur to empty\n","    \n","    #cv2_imshow(draw) #display image\n","    \n","    #print(count)\n","\n","    #building video\n","      \n","    cv2.imwrite(r\"/content/drive/MyDrive/keras-retinanet/temp/img%d.jpg\" % count, draw) #storing frame for future use in video\n","    images.append(\"/content/drive/MyDrive/keras-retinanet/temp/img{}.jpg\".format(count)) #storing frame address in array \n","    # cv2.imwrite(r\"/content/drive/MyDrive/keras-retinanet/temp/img.jpg\", draw)\n","    # # temp_frame = cv2.imread(r\"/content/drive/MyDrive/keras-retinanet/temp/img.jpg\")  #reading the current frame  again \n","    # # out.write(temp_frame)  #writing the frame to video\n","    # # os.remove(r\"/content/drive/MyDrive/keras-retinanet/temp/img.jpg\") #remove the stored frame\n","    count+=1  #increment frame count  to store image in temp\n","    \n","    key=cv2.waitKey(1)\n","    if(key==27):\n","        break\n","        \n","cv2.destroyAllWindows()\n","source.release()  #close video\n","\n","\n","#buliding video\n","\n","l=list(pat.split('/'))[-1]\n","l=list(l.split('.'))[0]\n","out_path='/content/drive/MyDrive/keras-retinanet/out_videos/'+l+\".mp4\"  #video output location\n","#print(out_path)\n","fps = 16  #video frames per second\n","\n","#print(images)  #print frame_address list\n","img = cv2.imread(images[0])  #read image\n","height, width, layers = img.shape #getting dimension of image\n","size = (width,height)\n","out = cv2.VideoWriter(out_path,cv2.VideoWriter_fourcc(*'DIVX'), fps, size) #start video input\n","for i in range(len(images)):  #traverse every address and add image\n","    #print(i,images[i])\n","    try:\n","      img = cv2.imread(images[i])\n","      out.write(img)  #writing to video\n","      os.remove(images[i])  #remove image from temp folder\n","    except:\n","      continue\n","\n"," \n","out.release()  #close video\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"9qM-qOPzWfz9","outputId":"328925d1-c287-439a-98e8-adf23581f462"},"source":["pwd"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/keras-retinanet'"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"ikQiu-qDdc0i"},"source":["##code to empty the crash_pics directory\n","import os\n","dirpath=\"/content/drive/MyDrive/keras-retinanet/crash_pics/\"\n","l=os.walk(dirpath)\n","for root, dirs, files in l:\n","    for file in files:\n","        os.remove(os.path.join(root, file))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pL6WPuRpVq3-"},"source":[""],"execution_count":null,"outputs":[]}]}